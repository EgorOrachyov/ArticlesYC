\subsection{Index Creation Algorithm}

The \textit{index creation} algorithm outputs the final adjacency matrix $\mathcal{M}_2$ for the input graph with all pairs of vertices which are reachable through some nonterminal in the input grammar $G$, as well as the index matrix $C_3$, which is to be used to extract paths in the \textit{path extraction} algorithm.

The algorithm is based on the generalization of the FSM intersection for an RSM,  and the edge-labeled directed input graph.
Since the RSM is composed as a set of FSMs, it could be easily presented as an adjacency matrix for some graph over labels set $\Sigma \cup S$.
As shown in the Def.~\ref{def:bool:product}, we can apply Kronecker product from Boolean matrices to \textit{intersect} the RSM and the input graph to some extent.
But the RSM contains the nonterminal symbols from $N$ with additional \textit{recursive calls} logic, which requires \textit{transitive closure} step to extract such symbols.

The core idea of the algorithm comes from Kronecker product and transitive closure.
The algorithm boils down to the iterative Kronecker product evaluation for the RSM adjacency matrix $\mathcal{M}_1$ and the input graph adjacency matrix $\mathcal{M}_2$, followed by transitive closure, extraction of nonterminals and updating the graph adjacency matrix $\mathcal{M}_2$.

% In this section, we introduce the algorithm for context-free path querying.
%The algorithm determines the existence of a path, which forms a sentence of the language defined by 
%the input RSM $R$, between each pair of vertices in the directed edge-labeled graph $\mathcal{G}$.
%The algorithm is based on the generalization of the FSM intersection for an RSM, 
%and an input graph. Since a graph can be interpreted as a FSM, in which 
%transitions correspond to the labeled edges between vertices of the graph, 
%and an RSM is composed of a set of FSMs, the intersection of such machines
%can be computed using the classical algorithm for FSM intersection, presented 
%in~\cite{automata:theory:10.5555/1177300}. 
%Such a way of generalization leads to zero-overhead algorithm for RPQ, contrary to other algorithms which require regular expression to context-free grammar transformation.

%The intersection can be computed as a Kronecker product of the corresponding 
%adjacency matrices for an RSM and a graph. Since we are only determining the
%reachability of vertices, it is enough to represent intersection result as 
%a Boolean matrix. It simplifies the algorithm implementation and allows 
%one to express it in terms of basic matrix operations.

\subsubsection{Na{\"i}ve Version}
Listing~\ref{tensor:cfpq} shows main steps of the algorithm.
The algorithm accepts context-free grammar $G=(\Sigma,N,P$) and graph $\mathcal{G}=(V,E,L)$ as an input.
Start nonterminal is not required here, since the algorithm allows to query paths, which are
reachable via some nonterminal from $N$.
An RSM $R$ is created from the grammar $G$.
Note, that $R$ must have no $\varepsilon$-transitions.
$\mathcal{M}_1$ and $\mathcal{M}_2$ are the Boolean adjacency matrices for the machine 
$R$ and the graph $\mathcal{G}$ correspondingly.

Then for each vertex $i$ of the graph $\mathcal{G}$, the algorithm adds loops 
with non-terminals, which allows deriving $\varepsilon$-word.
Here the following rule is implied: each vertex of the graph is reachable 
by itself through an $\varepsilon$-transition. Since the machine $R$ does 
not have any $\varepsilon$-transitions, the $\varepsilon$-word could be 
derived only if a state $s$ in the box $B$ of the $R$ is both initial and final.
This data is queried by the $getNonterminals$ function for each state $s$.

The algorithm terminates when the matrix $\mathcal{M}_2$ stops changing.
Kronecker product of matrices $\mathcal{M}_1$ and $\mathcal{M}_2$ is evaluated
for each iteration.
The result is stored in $\mathcal{M}_3$ as a Boolean matrix. Since we are interested
only in the reachability of some vertices, there is no need to store a separate
Boolean matrix for each label from $\Sigma \cup N$. Therefore, we can 
collapse it into single Boolean matrix $M'_3$, what is done in the next step.
This Boolean matrix could be interpreted as an adjacency matrix for some directed graph
without labels with the same set of the vertices, as in the graph formed by $\mathcal{M}_3$.
From that point of view the matrix $M'_3$ has the following property 
from its definition: if some vertices connected by some path in the graph $\mathcal{G}(M'_3)$ 
then these vertices are connected by one or many paths in the graph $\mathcal{G}(\mathcal{M}_3)$.

For the given $M'_3$ a $C_3$ transitive closure matrix
is evaluated by the corresponding function call. 
Then the algorithm iterates over cells of the $C_3$.
For the pair of indices $(i,j)$, it computes $s$ and $f$ --- 
the initial and final states in the recursive automata $R$ which relate 
to the concrete $C_3[i,j]$ of the closure matrix.
If the given $s$ and $f$ belong to the same box $B$ of $R$, $s = q_B^0$, 
and $f \in F_B$, then $getNonterminals$ returns the respective nonterminal.
Then for each such nonterminal the respective matrix of the graph adjacency 
matrix $\mathcal{M}_2$ is updated and a new edge as a Boolean value in the 
appropriate cell is added.

The functions $getStates$ and $getCoordinates$ (see Listing~\ref{tensor:cfpq:help})
are used to map indices between Kronecker product arguments and the result matrix.
The Implementation appeals to the blocked structure of the matrix $C_3$, 
where each block corresponds to some automata and graph edge.

The algorithm returns the computed path extraction index $C_3$ and 
the updated matrix $\mathcal{M}_2$, which contains the initial 
graph $\mathcal{G}$ data as well as data for nonterminals from $N$.
If a cell $M_2^S[i,j]$ for any valid indices $i$ and $j$ and $S \in N$ 
contains $\{1\}$, then vertex $j$ is reachable from vertex $i$ in grammar $G$ for 
nonterminal $S$.

\subsubsection{Index creation for RPQ}
In case of the RPQ, the main \textbf{while} loop takes only one iteration to actually
append data. Since the input query is provided in form of the regular expression, one
can construct the corresponding RSM, which consists of the single 
\textit{component state machine}. This CSM is built from the regular expression and labeled as 
the $S$ for example, which has no \textit{recursive calls}. The adjacency 
matrix of the machine is build over $\Sigma$ only. Therefore, calculating the 
Kronecker product, all relevant information is taken into account at the first 
iteration of the loop.

\begin{algorithm}[h]
\floatname{algorithm}{Listing}
\begin{algorithmic}[1]
\footnotesize
\caption{Kronecker product based CFPQ}
\label{tensor:cfpq}
\Function{contextFreePathQuerying}{G, $\mathcal{G}$}
    % Input data preparation
    \State{$R \gets$ Recursive automata for $G$}
    \State{$\mathcal{M}_1 \gets$ Boolean adjacency matrix for $R$}
    \State{$\mathcal{M}_2 \gets$ Boolean adjacency matrix for $\mathcal{G}$}
    \State{$C_3 \gets$ The empty matrix}
    % Eps-transition handling for graph
    \For{$s \in 0..dim(\mathcal{M}_1)-1$}
        \For{$S \in \textit{getNonterminals}(R,s,s)$}
            \For{$i \in 0..dim(\mathcal{M}_2)-1$}
                % Or just $M_2^n[i,i] \gets M_2^n[i,i] \vee \{1\}$ ??? 
                \State{$M_2^S[i,i] \gets \{1\}$}
            \EndFor
        \EndFor
    \EndFor
    \While{Matrix $\mathcal{M}_2$ is changing}
        % Kronecker product (i.e. partial intersection)
        \State{$\mathcal{M}_3 \gets \mathcal{M}_1 \otimes \mathcal{M}_2$}
        \Comment{Evaluate Kronecker product}
        % Collapse to single Boolean matrix
        \State{$M'_3 \gets \bigvee_{M_3^a \in \mathcal{M}_3} M_3^a $}
        \Comment{Collapse to Boolean matrix}
        % Closure over Boolean matrix only
        \State{$C_3 \gets \textit{transitiveClosure}(M'_3)$}
        \State{$n \gets$ dim($M_3)$}
        \Comment{Matrix $\mathcal{M}_3$ size = $n \times n$}
        % Add non-terminals (possibly new)
        \For{$(i,j) \in [0..n-1] \times [0..n-1]$}
            \If{$C_3[i,j]$}
                \State{$s, f \gets \textit{getStates}(C_3,i,j)$}
                \State{$x, y \gets \textit{getCoordinates}(C_3,i,j)$}
                \For{$S \in \textit{getNonterminals}(R,s,f)$}
                    \State{$M_2^S[x,y] \gets \{1\}$}
                \EndFor
            \EndIf
        \EndFor
    \EndWhile
\State \Return $\mathcal{M}_2,C_3$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
\floatname{algorithm}{Listing}
\begin{algorithmic}[1]
\footnotesize
\caption{Help functions for Kronecker product based CFPQ}
\label{tensor:cfpq:help}
\Function{getStates}{$C, i, j$}
    \State{$r \gets dim(\mathcal{M}_1)$}
    \Comment{$\mathcal{M}_1$ is adjacency matrices for $R$}
    \State \Return{$\left\lfloor{i / r}\right\rfloor, \left\lfloor{j / r}\right\rfloor$}
\EndFunction
\Function{getCoordinates}{$C, i, j$}
    \State{$n \gets dim(\mathcal{M}_2)$}
    \Comment{$\mathcal{M}_2$ is adjacency matrices for $\mathcal{G}$}
    \State \Return{$i \bmod n, j \bmod n$}
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{lemma}
    \label{lemma:algo:correctness}
    Let $\mathcal{G} = (V,E,L)$ be a graph and $G = \langle\Sigma, N, S, P\rangle$ be a grammar.
    Let $\mathcal{M}_{2,(k)}$ be an adjacency matrix $\mathcal{M}_2$ after the execution of some iteration $k \geq 0$ of the algorithm in Listing~\ref{tensor:cfpq}.
    Then for any valid indices $i, j$ and for each nonterminal $A \in N$ such that cell $M_{2,(k)}^A[i,j]$ contains $\{1\}$, the following statement holds: in the graph $\mathcal{G}$ $\exists i\pi j: A \xrightarrow{*} l(\pi)$.
\end{lemma}

\begin{proof}{(Proof by induction)}

    \textbf{Basis:} For $k = 0$ and the statement of the lemma holds, since
    $\mathcal{M}_{2,(0)} = \mathcal{M}_2$, where $\mathcal{M}_2$ is adjacency matrix of the graph $\mathcal{G}$. The nonterminals,
    which allow to derive $\varepsilon$-word, are also added at algorithm
    preprocessing step, since each vertex of the graph is reachable by itself 
    through an $\varepsilon$-transition.
    
    \textbf{Inductive step:} Assume that the statement of the lemma holds for any
    $k \leq (p - 1)$ and show that it also holds for $k = p$, where $p \geq 1$.
    
    For the algorithm iteration $p$ the Kronecker product $\mathcal{M}_3, M'_3$ and transitive
    closure $C_3$ are evaluated as described in the algorithm. By the properties
    of this operations, some edge $e = ((s,i),(f,j))$ exists in the directed
    graph, represented by adjacency matrix $C_3$, if and only if $\exists s
    \pi ^{'} f$ in the RSM graph, represented by matrix $\mathcal{M}_1$, and 
    $\exists i \pi j$ in graph, represented by $\mathcal{M}_{2,(p-1)}$. Concatenated symbols 
    along the path $\pi^{'}$ form some derivation string v, composed from terminals
    and non-terminals, where $v \xrightarrow{*} l(\pi)$  by the inductive assumption.
    
    The new $\{1\}$ will be added to the cell $M_{2,(k)}^A[i,j]$ only if $s$ and $f$ 
    are initial and final states of some box of the RSM corresponding to 
    the non-terminal $A$. In this case, the grammar $G$ has the derivation rule
    $A \to v$, and by the inductive assumption $v \xrightarrow{*} l(\pi)$. Therefore, 
    $A \xrightarrow{*} l(\pi)$ and this completes the proof of the lemma.
    
\end{proof}

\begin{lemma}
    \label{lemma:algo:completeness}
    Let $\mathcal{G} = (V,E,L)$ be a graph and $G = \langle\Sigma, N, S, P\rangle$ be a grammar. 
    Let $\mathcal{M}_{2,(k)}$ be an adjacency matrix $\mathcal{M}_2$ after the execution of some iteration $k \geq 0$ of the algorithm in Listing~\ref{tensor:cfpq}.
    For any path $i \pi j$ in the graph $\mathcal{G}$ with word $l = l(\pi)$ if 
    exists the derivation tree of $l$ from the nonterminal $A$ of the grammar $G$ with the height $h \leq k+1$, then $M_{2,(k)}^A[i,j]$ contains $\{1\}$.

\end{lemma}

\begin{proof}{(Proof by induction)}

    \textbf{Basis:} Show that statement of the lemma holds for the $k = 0$. Matrix
    $\mathcal{M}_{2,(0)} = \mathcal{M}_2$ and edges of the graph $\mathcal{G}$ contains only labels from $L$. 
    Since the derivation tree of height $h = k + 1 = 1$ contains only one non-terminal 
    $A$ as a root and only symbols from $\Sigma \cup {\varepsilon}$ as leafs, 
    for all paths, which form a word with derivation tree of the height $h = 1$, 
    the corresponding nonterminals will be added to the $M_{2,(0)}^A[i,j]$ via preprocessing step. Thus, the lemma statement holds for the $k = 1$.

    \textbf{Inductive step:} Assume that the statement of the lemma hold for any
    $k \leq (p - 1)$ and show that it also holds for $k = p$, where $p \geq 2$.
    
    For the algorithm iteration $p$ the Kronecker product $\mathcal{M}_3, M'_3$ and transitive
    closure $C_3$ are evaluated as described in the algorithm. By the properties
    of this operations, some edge $e = ((s,i),(f,j))$ exists in the directed
    graph, represented by adjacency matrix $C_3$, if and only if $\exists s
    \pi^{'} f$ in the RSM graph, represented by matrix $\mathcal{M}_1$, and 
    $\exists i \pi j$ in graph, represented by $\mathcal{M}_{2,(p-1)}$. 
    
    For any path $i \pi j$, such that exist derivation tree of height $h < p + 1$ 
    for the word $l(\pi)$ with root non-terminal $A$, the cell $M_{2,(p)}^A[i,j]$ contains $\{1\}$ by inductive assumption.
    
    Suppose, that exists derivation tree $T$ of height $h = p + 1$ with the root 
    non-terminal $A$ for the path $i \pi j$. The tree $T$ is formed as
    $A \to a_1 .. a_d, d \geq 1$ where $\forall x \in [1..d]$ $a_x$ is sub-tree of
    height $h_x \leq p$ for the sub-path $i_x \pi_x j_x$. 
    By inductive hypothesis, there exists path $\pi_x$ for each derivation sub-tree, 
    such that $i = i_1 \pi_1 i_2 .. i_{d} \pi_{d} j_{d} = j$ and concatenation 
    of these paths forms $i \pi j$, and the root nonterminals of 
    this sub-trees are included in the matrix $M_{2, (p - 1)}$. 
    
    Therefore, vertices $i_x ~\forall x \in [1..d]$ form path in the graph, 
    represented by matrix $\mathcal{M}_{2, (p-1)}$, with complete set of labels.
    Thus, new $\{1\}$ will be added to the cell $M_{2,(p)}^A[i,j]$ corresponding to the vertices $i$ and $j$ and nonterminal $A$. This completes the proof of the lemma.

\end{proof}

\begin{theorem}
    Let $\mathcal{G} = (V,E,L)$ be a graph and $G = \langle\Sigma, N, S, P\rangle$ be a grammar.
    Let $\mathcal{M}_{2}$ be resulting adjacency matrix after the execution of the algorithm in Listing~\ref{tensor:cfpq}. Then for any valid indices $i, j$ and for each nonterminal $A \in N$ the following statement holds: the cell $M_{2,(k)}^A[i,j]$ contains $\{1\}$, if and only if there is a path $i\pi j$ in the graph $\mathcal{G}$ such that $ A \xrightarrow{*} l(\pi)$.
\end{theorem}{}
    
\begin{proof}
    
    This theorem is a consequence of the  
    Lemma~\ref{lemma:algo:correctness} and 
    Lemma~\ref{lemma:algo:completeness}.
    
\end{proof}{}

\begin{theorem}{}
    Let $\mathcal{G} = (V,E,L)$ be a graph and $G = \langle\Sigma, N, S, P\rangle$ be a grammar.
    The algorithm in Listing~\ref{tensor:cfpq} terminates in finite number of steps.
\end{theorem}

\begin{proof}
    
    The main \textit{while-loop} in the algorithm is executed while graph adjacency 
    matrix $\mathcal{M}_2$ is changing. Since the algorithm only adds the edges with 
    non-terminals from $N$, the maximum required number of iterations 
    is $|N| \times |V| \times |V|$, where each component has finite size. 
    This completes the proof of the theorem.
    
\end{proof}{}

% TODO: more accurate upper bound for the algorithm complexity 

\subsubsection{Application of Dynamic Transitive Closure}

In this subsection we show how to reduce the time complexity of the algorithm in Listing~\ref{tensor:cfpq} by avoiding redundant calculations. 


It is easy to see that the most time-consuming steps of the algorithm are the Kronecker product and transitive closure computations.
Note that the adjacency matrix $\mathcal{M}_2$ is always changed incrementally i. e. elements (edges) are added to $\mathcal{M}_2$ (and are never deleted from it) at each iteration of the algorithm.
So it is not necessary to recompute the whole product or transitive closure if an appropriate data structure is maintained.


To compute the Kronecker product, we employ the fact that it is left-distributive.
Let $\mathcal{A}_2$ be a matrix with newly added elements and $\mathcal{B}_2$ be a matrix with the all previously found elements, such that $\mathcal{M}_2 = \mathcal{A}_2 + \mathcal{B}_2$.
Then by the left-distributivity of the Kronecker product we have $\mathcal{M}_1 \otimes \mathcal{M}_2 = \mathcal{M}_1 \otimes (\mathcal{A}_2 + \mathcal{B}_2) = \mathcal{M}_1\otimes \mathcal{A}_2 + \mathcal{M}_1 \otimes \mathcal{B}_2$.
Note that $\mathcal{M}_1 \otimes \mathcal{B}_2$ is known and is already in the matrix $\mathcal{M}_3$ and its transitive closure also is already in the matrix $C_3$, because it has been calculated at the previous iterations, so it is left to update some elements of $\mathcal{M}_3$ by computing $\mathcal{M}_1\otimes \mathcal{A}_2$.


The fast computation of transitive closure can be obtained by using incremental dynamic transitive closure technique. We use an approach by Ibaraki and Katoh~\cite{IBARAKI198395} to maintain dynamic transitive closure. The key idea of their algorithm is to recalculate reachability information only for those vertices, which become reachable after insertion of the certain edge (see Figure~\ref{edgeAdd} for details). The algorithm is presented in Listing~\ref{tensor:cfpq:dynamicTC} (we have slightly modified it to efficiently track new elements of the matrix $C_3$). 

\begin{algorithm}[h]
\floatname{algorithm}{Listing}
\begin{algorithmic}[1]
\footnotesize
\caption{The dynamic transitive closure procedure}
\label{tensor:cfpq:dynamicTC}
\Function{add}{$C_3, i, j$}
       \State{$n \gets$ Number of rows in $C_3$}
        \State{$C_3' \gets$ Empty matrix of size $n \times n$}
        \For{$u \neq 0 \in$ checkCondition($C_3, i, j$)}
        \State{newReachablePairs($C_3, C_3', u, j$)}
        \EndFor
        \State \Return $C_3'$
\EndFunction
 \Function{checkCondition}{$C_3, i, j$}
        \State{$A \gets$ Empty array of size $n$}
        \For{$u \in 0...n \mid  u \neq j $}
    \Comment{$1 \wedge 1 = 0 \wedge 0 = 1 \wedge 0 = 0$; $0 \wedge 1 = 1$}
       \State{ $A[u] = C_3[u,j] \wedge C_3[u,i]$}
        \EndFor
\State \Return $A$
\EndFunction
 \Function{newReachablePairs}{$C_3, C_3', u, j$}
      \State{$C_3'[u,v] = C_3[u, v] \wedge C_3[j, v]$}
 \Comment{$1 \wedge 1 = 0 \wedge 0 = 1 \wedge 0 = 0$; $0 \wedge 1 = 1$}
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{figure}
\begin{tikzpicture}[shorten >=1pt,node distance=2cm,on grid,auto] 
   \node[state] (q_0)   {$u$}; 
   \node[state] (q_1) [above right=of q_0] {$i$}; 
   \node[state] (q_2) [ right=of q_1] {$j$}; 
   \node[state] (q_3) [ below right=of q_2] {$v$}; 
    \path[->] 
    (q_0) edge[decorate, decoration={snake}]  node {} (q_1)
    (q_1) edge [thick]  node {} (q_2)
    (q_2) edge[decorate, decoration={snake}]  node {} (q_3)
    (q_0) edge [dashed]  node {} (q_3);        
\end{tikzpicture}

\caption{The vertex $j$ become reachable from the vertex $u$ after the addition of edge $(i, j)$. Then the vertex $v$ is reachable from $u$ after inserting the edge $(i, j)$ if $v$ is reachable from $j$.}
\label{edgeAdd}
\end{figure}

Final version of the modified algorithm from Listing~\ref{tensor:cfpq} is shown in Listing~\ref{tensor:cfpq:cubic}.

\begin{algorithm}[h]
\floatname{algorithm}{Listing}
\begin{algorithmic}[1]
\footnotesize
\caption{Kronecker product based CFPQ using dynamic transitive closure}
\label{tensor:cfpq:cubic}
\Function{contextFreePathQuerying}{G, $\mathcal{G}$}
    % Input data preparation
    \State{$n \gets$ The number of nodes in $\mathcal{G}$}
    \State{$R \gets$ Recursive automata for $G$}
    \State{$\mathcal{M}_1 \gets$ Boolean adjacency matrix for $R$}
    \State{$\mathcal{M}_2, \mathcal{A}_2 \gets$ Boolean adjacency matrix for $\mathcal{G}$}
    %\State{$M_3 \gets$ The empty matrix}
    \State{$C_3 \gets$ The empty matrix of size $|R|n \times |R|n$}
    % Eps-transition handling for graph
    \For{$s \in 0..dim(\mathcal{M}_1)-1$}
        \For{$S \in \textit{getNonterminals}(R,s,s)$}
            \For{$i \in 0..dim(\mathcal{M}_2)-1$}
                \State{$M^S_2[i,i] \gets 1 $}
            \EndFor
        \EndFor
    \EndFor
    \While{$\mathcal{M}_2$ is changing}
        \State{$M_3' \gets \bigvee_{M^S \in \mathcal{M}_1 \otimes \mathcal{A}_2} M^S$}
        %\State{$\mathcal{A}_2 \gets$ The empty matrix of size $n \times n$}
        \State{$\mathcal{A}_2 \gets$ The empty matrix}
        \State{$C_3' \gets$ The empty matrix of size $|R|n \times |R|n$}
        %\Comment{Evaluate Kroncker product}
        \For{$(i,j) \mid M_3'[i,j] \neq 0$}
            %\State{$C_3'[i,j] \gets 1$}
            \State{$C_3' \gets \textit{add}(C_3, C_3', i, j)$}
            \Comment{Updating the transitive closure}
            \State{$C_3 \gets C_3 + C_3'$}
        \EndFor
        %\State{$n \gets$ dim($M_3)$}
        %\Comment{Matrix $M_3$ size = $n \times n$}
        % Add non-terminals (possibly new)
        \For{$(i,j)\ |\ C_3'[i,j] \neq 0$}
                \State{$s, f \gets \textit{getStates}(C_3',i,j)$}
                \State{$x, y \gets \textit{getCoordinates}(C_3',i,j)$}
                \For{$S \in \textit{getNonterminals}(R,s,f)$}
                    \State{$M^S_2[x,y] \gets 1$}
                    \State{$A^S_2[x,y] \gets 1$}
                \EndFor
        \EndFor
    \EndWhile
\State \Return $\mathcal{M}_2, C_3$
\EndFunction
% \Function{add}{$C, C', i, j$}
%     \State{$C'[i,j] \gets {1}$}
%     \For{$(u,v) \mid C[u,i] = C[j,v] = 1, C[u,j] = C[u,v] = 0$}
%         \State{$C'[u,v] \gets {1}$}
%     \EndFor
%     \State \Return{$C'$}
% \EndFunction
\end{algorithmic}
\end{algorithm}
\begin{theorem}{}
    Let $\mathcal{G} = (V,E,L)$ be a graph and $G = \langle\Sigma, N, S, P\rangle$ be a grammar.
    The algorithm from Listing~\ref{tensor:cfpq:cubic} calculates a result matrices $\mathcal{M}_2$ and $C_3$ in ${|P|}^3n^3$ time where $n = |V|$.
\end{theorem}
\begin{proof}
 Let $|\mathcal{A}|$ be a number of non-zero elements in a matrix $\mathcal{A}$. Consider the total time which is needed for computing the Kronecker products. The elements of the matrices $\mathcal{A}_2^{(i)}$ are pairwise distinct on every $i$-th iteration of the algorithm therefore we have 
 $\sum\limits_i{T(\mathcal{M}_1 \otimes \mathcal{A}_2^{(i)})} = |\mathcal{M}_1| \sum\limits_i {|\mathcal{A}_2^{(i)}|} = (|N| + |\Sigma|){|P|}^2 \sum\limits_i {|\mathcal{A}_2^{(i)}|} \le {(|N| + |\Sigma|)}^2{|P|}^2 n^2$
 operations in total. 


Now we derive the time complexity of maintainig the dynamic transitive closure. Notice that $C_3$ has size of the Kronecker product of $\mathcal{M}_1 \otimes \mathcal{M}_1$, which is equal to $|R|n \times |R|n = |P|n \times |P|n$ so no more than ${|P|}^2n^2$ edges will be added during all iterations of the Algorithm. The function $checkCondition$ from the Listing~\ref{tensor:cfpq:dynamicTC} takes $O(|P|n)$ time for every inserted edge $(i, j)$. Thus we have $O({|P|}^2n^2|P|n ) = O({|P|}^3n^3)$ operations in total. The function $newReachablePairs$ requires $O(|P|n)$ time for a given vertex $u$. This operation is performed for every pair $(j, v)$ of vertices such that a vertex $j$ became reachable from the vertex $u$. The vertex $j$ become reachable from the vertex $u$ (and accordingly the value of the matrix cell $C_3[u, j]$ becomes $1$ from $0$) only once during the entire computation, so the function $newReachablePairs$ will be executed at most $O({|P|}^2n^2)$ times for every $u$ and hence $O({|P|}^3n^3)$ times in total for all vertices. Therefore $O({|P|}^3n^3)$ operations are performed to maintain dynamic transitive closure during all iteration of the algorithm from Listing~\ref{tensor:cfpq:cubic}.


Notice that the matrix $C_3'$ contains only new elements, therefore $C_3$ can be updated directly using only $|C_3'|$ operations and hence $O({|P|}^2n^2)$ operations in total. The same holds for cycle in line 18 of the algorithm from Listing~\ref{tensor:cfpq:cubic}, because operations are performed only for non-zero elements of the matrix $|C_3'|$. Finally, we have that the time complexity of the algorithm is ${(|N| + |\Sigma|)}^2{|P|}^2 n^2 + O({|P|}^3n^3) + O({|P|}^2n^2) + O({|P|}^2n^2)= O({|P|}^3n^3)$.
\end{proof}{}

\subsubsection{Speeding up by a factor of $\log n$}

In this subsection we use the Four Russians' trick to speed up the dynamic transitive closure algorithm from the Listing~\ref{tensor:cfpq:dynamicTC}.
\begin{theorem}{}
    The computation of transitive closure matrices can be done in $O(n^3/\log n)$ time when $n^2$ edges are added to the graph.
\end{theorem}
\begin{proof}
Consider the function $checkCondition$ from the Listing~\ref{tensor:cfpq:dynamicTC}. Its operations are equivalent to the element-wise (Hadamard) product of two vectors of size $n$, where multiplication operation is denoted as $\wedge$ and has the following properties: $1 \wedge 1 = 0 \wedge 0 = 1 \wedge 0 = 0$ and $0 \wedge 1 = 1$. The first vector represents reachability of the given vertex $i$ from other vertices $\{u_1, u_2, ..., u_n\}$ of the graph and the second vector represents the same for the given vertex $j$. The function $newReachablePairs$ also can be reduced to the computation of the Hadamard product of two vectors of size $n$ for a given $u_k$. The first vector contains the information whether vertices  $\{v_1, v_2, ..., v_n\}$ of the graph are reachable from the given vertex $u_k$ and the second vector represents the same for the given vertex $j$. The element-wise product of two vectors can be calculated naively in time $O(n)$ which gives the $O(n^3)$ time for maintaining the transitive closure. Thus, the time complexity of the transitive closure can be reduced by speeding up element-wise product of two vectors of size $n$. 


To achieve this goal, we use the Four Russians' trick. Split each vector into $n/\log n$ parts of size $\log n$. Create a table $S$ such that $S(a, b)$ = $a \wedge b$ where $a, b \ \in {\{0,1\}}^{\log n}$. This takes a time $O(n^2 \log n)$, since there are $2^{\log n} = n$ variants of Boolean vectors of size $\log n$ and hence $n^2$ possible pairs of vectors $(a, b)$ in total, and each component takes $O(\log n)$ time. With table $S$, we can calculate product of two parts of size $\log n$ in constant time. There are $n/\log n$ such parts, so the element-wise product of two vectors of size $n$ can be calculated in time $O(n/\log n)$ with $O(n^2 \log n)$ preprocessing. This gives us a dynamic transitive closure algorithm running in time $O(n^3/\log n)$: both of the functions $checkCondition$ and  $newReachablePairs$ are evaluated no more than $O(n^2)$ times during the whole computation, and each function calculates Hadamard product of two vectors in $O(n/\log n)$ time.
\end{proof} 
Notice that the maintaining of the dynamic transitive closure dominates the cost of the algorithm from Listing~\ref{tensor:cfpq:cubic}, therefore we immediately deduce the following.
\begin{corollary}{}
    Let $\mathcal{G} = (V,E,L)$ be a graph and $G = \langle\Sigma, N, S, P\rangle$ be a grammar.
    The resulting matrices $\mathcal{M}_2$ and $C_3$ can be calculated in $O({|P|}^3n^3/(\log n + \log |P|))$ time.
\end{corollary}


Finally, we formulate the theorem which connects the time complexity of CFPQ and time complexity of specific incremental transitive closure of a directed graph.
\begin{theorem}{Subcubic incremental transitive closure leads to subcubic CFPQ.}
\label{theorem:subcubicTC}
Suppose the incremental transitive closure problem where only insertion queries are allowed and the result of each insertion is a set of newly connected pairs. If one can solve this problem in $O(n^{3-\varepsilon})$ total time for $n^2$ insertions, then one can solve CFPQ in $O(n^{3-\varepsilon})$, where $n$ is a number of vertices in the graph in both cases. 
\end{theorem}
Theorem~\ref{theorem:subcubicTC} shows that the maintaining of the incremental transitive closure dominates the cost of the algorithm. Thus, CFPQ can be solved in truly subcubic $O(n^{3-\varepsilon})$ time if there is an incremental dynamic algorithm for the transitive closure for a graph with $n$ vertices with preprocessing time $O(n^{3-\varepsilon})$ and total update time $O(n^{3-\varepsilon})$. Unfortunately, such an algorithm is unlikely to exist: it was proven that there is no incremental dynamic transitive closure algorithm for a graph with $n$ vertices and at most $m$ edges with preprocessing time $poly(m)$, total update time $mn^{1-\varepsilon}$, and query time $m^{\delta-\varepsilon}$ for any $\delta \in (0, 1/2]$ per query that has an error probability of at most 1/3 assuming the widely believed Online Boolean Matrix-Vector Multiplication (OMv) Conjecture~\cite{10.1145/2746539.2746609}. OMv Conjecture introduced by Henzinger et al. ~\cite{10.1145/2746539.2746609} states that for any constant $ \varepsilon>0$, there is no $O(n^{3-\varepsilon})$-time algorithm that solves OMv with an error probability of at most 1/3. 
