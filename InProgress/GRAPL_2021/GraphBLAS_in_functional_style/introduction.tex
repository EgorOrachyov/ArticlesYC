\section{introduction}

One of the promising ways to high-performance graph analysis is based on utilization of linear algebra: operations over vectors and matrices can be efficiently implemented on modern parallel hardware, and once we reduce given graph analysis problem to composition of such operations, we get high-performance solution for our problem. 
Well-known example of such reduction is a reduction of all-pairs shortest path (APSP) problem to matrix multiplication over appropriate \textit{semiring}.
GraphBLAS API standard~\cite{7761646} provides formalization, generalization of this observation and make it useful in practice. 
GraphBLAS API introduces appropriate algebraic structures (monoid, semiring), objects (scalar, vector, matrix), and operations over them to provides building blocks to create graph analysis algorithms.
It was shown, that sparse linear algebra over specific semirings is useful not only for graph analysis, but also in other areas, such as computational biology~\cite{10.5555/3433701.3433800} and machine learning~\cite{8091098}.

Reference implementation SuiteSarse:GraphBLAS~\cite{10.1145/3322125} is written in C and is used in a number of projects, such as RedisGraph, !!!.
Other implementations: CombBLAS, !!! .

GPGPU for high-performance analysis of huge amount of data. 
GraphBLAST~\cite{yang2019graphblast} --- GraphBLAST in CUDA C. 
GPGPU implementation of GraphBLAS API is challenging. 
Problems with polymorphic operations in OpenCL C and, as a result, with support of user-defined semirings.
Memory traffic.
Global optimizations (kernel fusion).

High-level programming languages for application development vs low-level for high-performance programming.
Moreover, specific languages for GPGPU programming: CUDA C, OpenCL C.
Problems with types, compositionality, optimizations (kernel fusion).

Functional programming. 
Type systems.
Optimizations.
Futhark~\cite{Henriksen:2017:FPF:3062341.3062354}, kernel fusion, specialization, deforestation etc. 


In this work we discuss a way to implement GraphBLAS API which combines high-performance computations on GPGPU and power of high-level programming languages in both application development and possible code optimizations.
Our solution is based on metaprogramming techniques: we propose to generate code for GPGPU from high-level programming language.
Namely, we plan to generate OpenCL C form a subset of  F\# programming language.
Usage of F\# simplifies both implementation of GraphBLAS API, and its utilization in application development. 
Moreover it should makes possible to use advanced optimization techniques, like kernel fusion, on the same way, as proposed, for example, in the Futhark programming language.
Choice of OpenCL C as a target language is motivated by its portability: it is possible to run OpenCL C code on multythread CPU, on different GPGPUs (not only Nvidia), and even on FPGA~\cite{kenter2019invited, 6567546}.
Utilization of FPGAs may open a way to hardware acceleration of sparse linear algebra and, as a result, of many solutions in different areas such as graph analysis, computational biology, machine learning.
Brahma.FSharp\footnote{!!!}.
Our preliminary evaluation shows that !!!