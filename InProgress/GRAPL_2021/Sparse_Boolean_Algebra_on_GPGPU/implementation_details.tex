\section{Implementation Details}

In this section we discuss the particular implementation details of the proposed libraries. Although general and architectural specifics are similar, the actual internal storage formats and algorithms are different. With this development strategy we address the potential problem of processing the sparse data with different values distribution, as well as the problem of proper balancing between time of the execution and memory consumption. 

\subsection{cuBool}

cuBool is sparse boolean linear algebra implementation specifically for NVIDIA Cuda platform. Core of this 
library relies on Cuda C/C++ language and API, what with NVCC compiler allows intermix C++ with Cuda 
specifics. Also cuBool employs NVIDIA Thrust auxiliary library, which provides 
implementation for generic data containers and operations, such as \textit{iterating}, \textit{exclusive or 
inclusive scan}, \textit{map} and etc., which are executed on Cuda device. That allows express algorithms in 
terms of high-level optimised primitives, what increases code readability and reduces time for development.

Sparse matrix is stored in the \textit{compressed sparse row} (CSR) format with only two arrays: 
$rowspt$ for row offset indices and $cols$ for columns indices. Boolean matrices has no actual values, thus 
$1$ values are encoded only as $(i, j)$ pairs. It allows to store matrix $M$ of size $m \times n$ 
in $(m + \textit{nnz(M)}) \times \textit{sizeof(index\_t)}$ bytes of GPU memory, where 
\textit{index\_t} is type of stored indices, for simplicity can be selected as \textit{uint32\_t}.

The algorithm Nspasrse~\cite{inproceedings:cfpq_for_redis_graph} is used for matrix-matrix multiplication. 
This algorithm is a boolean values case adaptation of the state-of-the-art, efficient and memory saving sparse general matrix multiplication (SpGEMM) algorithm, proposed in Yusuke Nagasaka et al. research~\cite{algo:spgemm:8025284}. 
This algorithm was selected because it gives promising relatively small memory footprint for large matrices processing, as well as it competes with other major Cuda SpGEMM implementations, such as cuSPARSE or CUSP.  

Matrix-matrix addition is based on GPU Merge Path algorithm~\cite{inproceedings:gpu_merge_path} with dynamic work balancing and two pass processing. 
These optimizations give better workload dispatch among execution blocks and allow more precise memory allocations in
order to keep memory footprint small respectively. 

% As an example of library C API embedding, cuBool provides python wrapper, called Pycubool. This module exports 
% library functionality via default CTypes module for native functions calling and provides safe and automated 
% management for native resources. 

\subsection{clBool}

clBool is sparse boolean linear algebra implementation for OpenCL platform. This library is implemented 
in the C++ with OpenCL kernels, stored as separate source files, loaded on demand at runtime. 

Sparse matrix primitive is stored in \textit{coordinate format} (COO) with two arrays: $rows$ and $cols$ 
for row and column indices of the stored non-zero values. For the matrix $M$ of size $m \times n$ memory 
consumption is $2 \times \textit{nnz(M)} \times \textit{sizeof(index\_t)}$. This format was selected 
instead of CSR, because COO gives better memory footprint for very sparse matrices with a lot of empty rows.

Matrix-matrix multiplication implementation is based on the algorithm, proposed in Weifeng Liu et al. research~\cite{DBLP:journals/corr/0002V15a:spframework}. 
It is multi-step algorithm with dynamic workload balancing, which operates on CSR matrices. 
Since clBool primary primitive is COO matrix, before actual matrix-matrix multiplication the input matrices are converted into
\textit{doubly compressed sparse row} (DCSR) format, described in A. Buluc et al. work~\cite{4536313:about:dcsr}.
This algorithm is suitable for OpenCL implementation, what is confirmed with its utilisation in clSPARSE library.

Matrix-matrix addition is based on GPU Merge Path algorithm as well. Since all COO matrix values are stored in 
the continuous manner, its merge can be completed at single time, compared to CSR matrix merge computed on a 
per row basis. This operation is implemented in a classic one pass fashion: it allocates single merge 
buffer of size $\textit{nnz(A)} + \textit{nnz(B)})$ before actual merge of matrices $A$ and $B$, what can
negatively affect memory consumption for large matrices with lots of duplicated non-zero values at the 
same positions.
