\section{Implementation Details}

% Details on implementation. 
% Architecture.

% TODO:
% - stunning architecture diagram
% - exciting example of usage
% - unbelievable python API showcase 

Implemented sparse boolean linear algebra libraries for OpenCL and NVIDIA Cuda platforms are called
\textit{clBool} and \textit{cuBool} respectively. Source code and related artefacts are available at GitHub 
hosting~\cite{todo1, todo2}. Libraries are written in the C++ programming language, which is well-suited  performance and resource critical computational tasks. Libraries expose C compatible API with 
relatively small amount of functions and primitives, what gives expressiveness and allows to embed that API 
into other execution environments via interoperability mechanisms, for example, into Python or .NET runtimes. 
Libraries source code compilation is configured with CMake tool. Compilation process is 
straightforward and requires setup of only basic components and instruments, such as compiler, build 
configuration tools and platform-specific development kits.

Libraries operate on boolean semiring with values set \{\textit{true}, \textit{false}\} with \textit{false} as 
a neutral element, '+' operation defined as logical \textit{or} and '*' defined as logical \textit{and}. Values are also denoted as $\{1,~0\}$ respectively, and the abbreviation $\textit{NNZ(M)}$ gives the number of non-zero cells of the matrix $M$.

Main primitive is sparse matrix of boolean values, stored in one of the sparse formats. Sparse vector 
primitive is not presented, since its utilization is relatively rare presented in practical computational 
tasks. But its support is something to be added in far future. Primary available operations and functions are following.

\begin{itemize}
    \item Create sparse matrix $M$ of size $m \times n$.
    \item Delete sparse matrix $M$ and release all its internal resources.
    \item Fill the matrix $M$ with values $L = \{(i,j)_k\}_k$. The result of this operation is $M_{i,j} = 
    \textit{true}$ for each $(i, j) \in L$, and $M_{i,j} = \textit{false}$ for the rest of matrix values.
    \item Read matrix $M$ values $L = \{(i, j)~|~M_{i,j} = \textit{true}\}$.
    \item Matrix-matrix multiply-add operation $C \mathrel{+}= M \times N$.
    \item Matrix-matrix add operation $M \mathrel{+}= N$.
    \item Matrix-matrix Kronecker product $K = M \otimes N$.
\end{itemize}

\subsection{cuBool}

cuBool is sparse boolean linear algebra implementation specifically for NVIDIA Cuda platform. Core of this 
library relies on Cuda C/C++ language and API, what with NVCC compiler allows intermix C++ with Cuda 
specifics. Also cuBool employs NVIDIA Thrust auxiliary library, which provides 
implementation for generic data containers and operations, such as \textit{iterating}, \textit{exclusive or 
inclusive scan}, \textit{map} and etc., which are executed on Cuda device. That allows express algorithms in 
terms of high-level optimised primitives, what increases code readability and reduces time for development.

Sparse matrix primitive is stored in the \textit{compressed sparse row} (CSR) format with only two arrays: 
$rowspt$ for row offset indices and $cols$ for columns indices. Boolean matrices has no actual values, thus 
$true$ values are encoded only as $(i, j)$ pairs. It allows to store matrix $M$ of size $m \times n$ 
in $(m + \textit{NNZ(M)}) \times \textit{sizeof(IndexType)}$ bytes of GPU memory, where 
\textit{IndexType} is type of stored indices, for simplicity can be selected as \textit{uint32\_t}.

The algorithm Nspasrse~\cite{inproceedings:cfqp_for_redisgraph} is used for matrix-matrix multiplication. 
This algorithm is a boolean values case 
adaptation of the state-of-the-art, efficient and memory saving sparse general matrix multiplication (SpGEMM) 
algorithm, proposed in Yusuke Nagasaka et al. research~\cite{algo:spgemm:8025284}. This algorithm was selected because it 
gives promising relatively small memory footprint for large matrices processing, as well as it competes with 
other major Cuda SpGEMM implementations, such as cuSPARSE or CUSP.  

Matrix-matrix addition is based on GPU Merge Path algorithm~\cite{inproceedings:gpu_merge_path} with 
dynamic work balancing and two pass processing. 
These optimizations give better workload dispatch among execution blocks and allow more precise memory allocations in
order to keep memory footprint small respectively. 

As an example of library C API embedding, cuBool provides python wrapper, called Pycubool. This module exports 
library functionality via default CTypes module for native functions calling and provides safe and automated 
management for native resources. 

\subsection{clBool}

clBool is sparse boolean linear algebra implementation for OpenCL platform. This library is implemented 
in the C++ with OpenCL kernels, stored as separate source files, loaded on demand at runtime. 

Sparse matrix primitive is stored in \textit{coordinate format} (COO) with two arrays: $rows$ and $cols$ 
for row and column indices of the stored non-zero values. For the matrix $M$ of size $m \times n$ memory 
consumption is $2 \times \textit{NNZ(M)} \times \textit{sizeof(IndexType)}$. This format was selected 
instead of CSR, because COO gives better memory footprint for very sparse matrices with a lot of empty rows.

\textbf{!!! Matrix-matrix multiplication !!!}

Matrix-matrix addition is based on GPU Merge Path algorithm as well. Since all COO matrix values are stored in 
the single array, its merge can be completed at single time, compared to CSR matrix merge computed on a 
per row basis. This operation is implemented in a classic one pass fashion: it allocates single merge 
buffer of size $\textit{NNZ(A)} + \textit{NNZ(B)})$ before actual merge of matrices $A$ and $B$, what can
negatively affect memory consumption for large matrices with lots of duplicated non-zero values at the 
same positions.

\textbf{!!! Something about managed environment wrapper !!!}
