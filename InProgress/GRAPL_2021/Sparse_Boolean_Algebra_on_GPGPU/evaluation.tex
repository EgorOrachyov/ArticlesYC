\section{Evaluation}

% Evaluation of the proposed implemenation(s).

% What we need:
% - idea of the evaluation
% - what we want to show and measure
% - time performance, memory consumption, ops/per sec
% - what data we need?
% - very sparse, different distributions

We evaluate the applicability of the proposed libraries for analysis of some real-world matrix data.
The experiments are designed as computational tasks, that arise as stand-alone or intermediate steps in the solving of practical problems.

For evaluation, we used a PC with Ubuntu 20.04 installed.
It has Intel core i7-4790 CPU, 3.6GHz, DDR4 32Gb RAM and GeForce GTX 1070 GPU with 8Gb VRAM.
We measure only the execution time of the operations themselves.
The actual data is assumed to be loaded into the VRAM or RAM respectively in the appropriate format, required for the target tested framework.
Time to load data from the disc and prepare initial matrices state is excluded from the time measurements.

We use four sparse matrix libraries, CUSP, cuSPARSE, clSPARSE for GPU and SuiteSparse for CPU.
CUSP provides a template based implementation for operations, however it does not provide extra optimizations especially for boolean case values. cuSPARSE and clSPARSE both provide operations only for general types, such as float or double.
However this limitation can be ignored, if we consider non-zero float values as \textit{true}.
SuiteSparse is a GraphBLAS API reference implementation for CPU with built-in boolean semiring.

For performance evaluations, we selected $10$ various square matrices, which are widely used for sparse matrices benchmarks, from the Sparse Matrix Collection at University of Florida\footnote{T. Davis. The SuiteSparse Matrix Collection (the University of Florida Sparse Matrix Collection). Home page: \url{https://sparse.tamu.edu/}. Access date: 23.01.2021.}.
Information about matrices is summarized in table~\ref{table:sparse_matrices}.

{\setlength{\tabcolsep}{0.3em}
\begin{table}
\centering
{
\caption{Sparse matrix data for evaluation}
\label{table:sparse_matrices}
\scriptsize
\rowcolors{2}{black!2}{black!10}
\begin{tabular}{|l|c|c|c|c|}
\hline
Matrix $M$           & $\# Rows$    & Nnz of $M$   & Nnz of $M^2$   & Nnz of $M + M^2$ \\
\hline
\hline
1.  wing             &    62,032    &   243,088    &    714,200     &    917,178       \\
2.  luxembourg\_osm  &   114,599    &   239,332    &    393,261     &    632,185       \\
3.  amazon0312       &   400,727    & 3,200,400    & 14,390,544     & 14,968,909       \\
4.  amazon-2008      &   735,323    & 5,158,388    & 25,366,745     & 26,402,678       \\
5.  web-Google       &   916,428    & 5,105,039    & 29,710,164     & 30,811,855       \\
6.  roadNet-PA       & 1,090,920    & 3,083,796    &  7,238,920     &  9,931,528       \\
7.  roadNet-TX       & 1,393,383    & 3,843,320    &  8,903,897     & 12,264,987       \\
8.  belgium\_osm     & 1,441,295    & 3,099,940    &  5,323,073     &  8,408,599       \\
9.  roadNet-CA       & 1,971,281    & 5,533,214    & 12,908,450     & 17,743,342       \\
10. netherlands\_osm & 2,216,688    & 4,882,476    &  8,755,758     & 13,626,132       \\ 
\hline
\end{tabular}
}
\end{table}
}

The results of the evaluation are summarized in tables~\ref{table:eval_mm_results} and~\ref{table:eval_ma_results}.
Time is measured in milliseconds. 
Peak VRAM memory usage is measured in megabytes.
The result for each experiment is averaged over 10 runs.
The cell is left blank if the time operation is not implemented by a library.

The first experiment is intended to measure the performance of the matrix-matrix multiplication as $M \times M$.
The results are presented in the table~\ref{table:eval_mm_results}.
We can see that cuBool shows generally best performance among competitors.
clBool has good performance as well, comparable to cuSPRASE or CUSP for high density data.  
Memory consumption for cuBool and clBool is relatively small compared to CUSP and clSPARSE. 

The second experiment is intended to measure performance of the element-wise matrix-matrix addition as $M + M^2$,
where evaluation of the matrix $M^2$ is excluded from measurements.
The results are presented in the table~\ref{table:eval_ma_results}.
The numbers obtained in this experiment are more ambiguous than in the previous experiment.
cuBool, CUSP and cuSPARSE show nearly best performance among almost all experiments.
However, CUSP and cuSPRASE have significant memory consumption,
which can negatively affect on processing of large data.
clBool generally keeps its results within acceptable limits.
However, it still lags behind SuiteSparse. 
There is still space for optimizations, so it requires a deep investigation in our future research.

% It is worth mentioning, that CUSP matrix-matrix addition implementation has significant memory consumption, which can negatively affect on processing of huge data.
% cuSPARSE performance can degrade in such case as well, since its implementation is based on hashing, which is very sensitive for out-of shared blocks memory access for large data processing.

{\setlength{\tabcolsep}{0.25em}
\begin{table}[t]
\centering
{
\caption{Matrix-matrix multiplication evaluation results\\(milliseconds, megabytes).}
\label{table:eval_mm_results}
\scriptsize
\rowcolors{2}{black!2}{black!10}
\begin{tabular}{| c | c c | c c | c c | c c | c c | c |}
\hline
\multirow{2}{*}{$M$} & \multicolumn{2}{|c|}{CuBool} & \multicolumn{2}{|c|}{CUSP} & \multicolumn{2}{|c|}{CuSprs} & \multicolumn{2}{|c|}{ClBool} & \multicolumn{2}{|c|}{ClSprs} & \multicolumn{1}{|c|}{SuiteSprs} \\   
\cline{2-12} & Time & Mem & Time & Mem  & Time & Mem & Time & Mem & Time & Mem  & Time \\
\hline
\hline
1.           & 2.25 & 215 & 5.83 & 125  & 20.2 & 155 & 60.5 & 95  & 127  & 109  & 10.0 \\ % 1.  wing             
2.           & 2.97 & 213 & 4.17 & 111  & 1.78 & 149 & 16.0 & 91  & 10.8 & 99   & 2.53 \\ % 2.  luxembourg\_osm  
3.           & 24.6 & 215 & 110  & 897  & 411  & 301 & 97.6 & 279 & 65.7 & 459  & 238  \\ % 3.  amazon0312       
4.           & 38.9 & 341 & 173  & 1409 & 182  & 407 & 110  & 401 & 104  & 701  & 339  \\ % 4.  amazon-2008      
5.           & 50.1 & 341 & 240  & 1717 & 4756 & 439 & 277  & 491 & 409  & 1085 & 644  \\ % 5.  web-Google       
6.           & 21.7 & 215 & 43.3 & 481  & 37.6 & 247 & 45.6 & 203 & 85.5 & 283  & 63.0 \\ % 6.  roadNet-PA       
7.           & 26.6 & 215 & 52.1 & 581  & 46.8 & 271 & 55.8 & 229 & 107  & 329  & 74.9 \\ % 7.  roadNet-TX       
8.           & 26.9 & 215 & 33.8 & 397  & 26.7 & 235 & 68.6 & 183 & 104  & 259  & 57.8 \\ % 8.  belgium\_osm     
9.           & 37.6 & 215 & 76.4 & 771  & 67.2 & 325 & 77.7 & 279 & 151  & 433  & 110  \\ % 9.  roadNet-CA       
10.          & 40.4 & 215 & 51.9 & 585  & 51.1 & 291 & 78.1 & 251 & 158  & 361  & 93.0 \\ % 10. netherlands\_osm  
\hline
\end{tabular}
}
\end{table}
}

{\setlength{\tabcolsep}{0.25em}
\begin{table}[t]
\centering
{
\caption{Element-wise matrix-matrix addition evaluation results\\(milliseconds, megabytes).}
\label{table:eval_ma_results}
\scriptsize
\rowcolors{2}{black!2}{black!10}
\begin{tabular}{| c | c c | c c | c c | c c | c c | c |}
\hline
\multirow{2}{*}{$M$} & \multicolumn{2}{|c|}{CuBool} & \multicolumn{2}{|c|}{CUSP} & \multicolumn{2}{|c|}{CuSprs} & \multicolumn{2}{|c|}{ClBool} & \multicolumn{2}{|c|}{ClSprs} & \multicolumn{1}{|c|}{SuiteSprs} \\   
\cline{2-12} & Time & Mem & Time & Mem & Time & Mem & Time & Mem & Time & Mem & Time \\
\hline
\hline
1.           & 1.14 & 97  & 1.58 & 103 & 2.47 & 163 & \cho{22.8} & 105 & - & - & 4.06 \\ % 1.  wing             
2.           & 1.79 & 103 & 1.18 & 103 & 0.92 & 159 & \cho{4.52} & 103 & - & - & 1.56 \\ % 2.  luxembourg\_osm  
3.           & 9.44 & 237 & 16.5 & 455 & 24.1 & 405 & \cho{84.0} & 543 & - & - & 35.1 \\ % 3.  amazon0312       
4.           & 16.2 & 347 & 29.1 & 723 & 23.6 & 595 & \cho{163 } & 877 & - & - & 61.2 \\ % 4.  amazon-2008      
5.           & 18.7 & 379 & 32.3 & 815 & 88.7 & 659 & \cho{176 } & 989 & - & - & 72.5 \\ % 5.  web-Google       
6.           & 15.4 & 207 & 11.6 & 329 & 11.8 & 317 & \cho{66.4} & 359 & - & - & 34.0 \\ % 6.  roadNet-PA       
7.           & 19.3 & 231 & 14.0 & 385 & 14.7 & 357 & \cho{73.2} & 429 & - & - & 41.8 \\ % 7.  roadNet-TX       
8.           & 19.6 & 197 & 10.2 & 303 & 10.3 & 297 & \cho{61.8} & 321 & - & - & 26.8 \\ % 8.  belgium\_osm     
9.           & 27.1 & 289 & 19.5 & 513 & 20.3 & 447 & \cho{135 } & 579 & - & - & 61.4 \\ % 9.  roadNet-CA       
10.          & 33.1 & 263 & 15.2 & 423 & 18.2 & 385 & \cho{76.1} & 457 & - & - & 47.0 \\ % 10. netherlands\_osm  
\hline
\end{tabular}
}
\end{table}
}